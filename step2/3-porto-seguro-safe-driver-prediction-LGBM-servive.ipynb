{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (portalocker 2.0.0 (/anaconda/envs/azureml_py36/lib/python3.6/site-packages), Requirement.parse('portalocker~=1.0'), {'msal-extensions'}).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.11.0 to work with mlops-aml\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porto_seguro_safe_driver_model version: 3\n",
      "\t learning_rate : 0.02\n",
      "\t boosting_type : gbdt\n",
      "\t objective : binary\n",
      "\t metric : auc\n",
      "\t sub_feature : 0.7\n",
      "\t num_leaves : 60\n",
      "\t min_data : 100\n",
      "\t min_hessian : 1\n",
      "\t verbose : 0\n",
      "\t auc : 0.6377511613946426\n",
      "\n",
      "\n",
      "driver_model.pkl version: 2\n",
      "\t auc : 0.6377511613946426\n",
      "\n",
      "\n",
      "porto_seguro_safe_driver_model version: 2\n",
      "\t learning_rate : 0.02\n",
      "\t boosting_type : gbdt\n",
      "\t metric : auc\n",
      "\t objective : binary\n",
      "\t sub_feature : 0.7\n",
      "\t min_data : 100\n",
      "\t num_leaves : 60\n",
      "\t min_hessian : 1\n",
      "\t verbose : 0\n",
      "\t auc : 0.6377511613946426\n",
      "\n",
      "\n",
      "porto_seguro_safe_driver_model version: 1\n",
      "\n",
      "\n",
      "driver_model.pkl version: 1\n",
      "\t auc : 0.6377511613946426\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porto_seguro_safe_driver_model version 3\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['porto_seguro_safe_driver_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver-service folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_name = 'driver-service'\n",
    "\n",
    "# Create a folder for the web service files\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "print(folder_name, 'folder created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependency info in driver-service/driver_env.yml\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "- lightgbm\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "myenv.add_conda_package(\"lightgbm\")\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = folder_name + \"/driver_env.yml\"\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   source_directory = folder_name,\n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"driver_env.yml\")\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service_name = \"driver-service\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n",
      "2020-08-28T20:56:34,888398179+00:00 - iot-server/run \n",
      "2020-08-28T20:56:34,889038976+00:00 - rsyslog/run \n",
      "2020-08-28T20:56:34,889506175+00:00 - gunicorn/run \n",
      "2020-08-28T20:56:34,891288068+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-08-28T20:56:35,074847956+00:00 - iot-server/finish 1 0\n",
      "2020-08-28T20:56:35,075975652+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (13)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 40\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2020-08-28 20:56:36,188 | root | INFO | Starting up app insights client\n",
      "Starting up app insights client\n",
      "2020-08-28 20:56:36,188 | root | INFO | Starting up request id generator\n",
      "Starting up request id generator\n",
      "2020-08-28 20:56:36,188 | root | INFO | Starting up app insight hooks\n",
      "Starting up app insight hooks\n",
      "2020-08-28 20:56:36,188 | root | INFO | Invoking user's init function\n",
      "Invoking user's init function\n",
      "2020-08-28 20:56:36,769 | root | INFO | Users's init has completed successfully\n",
      "Users's init has completed successfully\n",
      "2020-08-28 20:56:36,772 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2020-08-28 20:56:36,772 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2020-08-28 20:56:36,773 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "Scoring timeout is found from os.environ: 60000 ms\n",
      "2020-08-28 20:56:53,498 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-08-28 20:56:53,499 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [28/Aug/2020:20:56:53 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2020-08-28 20:57:01,393 | root | INFO | Swagger file not present\n",
      "Swagger file not present\n",
      "2020-08-28 20:57:01,395 | root | INFO | 404\n",
      "404\n",
      "127.0.0.1 - - [28/Aug/2020:20:57:01 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.state)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver-service\n"
     ]
    }
   ],
   "source": [
    "for webservice_name in ws.webservices:\n",
    "    print(webservice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver [0, 1, 8, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 12, 1, 0, 0, 0.5, 0.3, 0.610327781, 7, 1, -1, 0, -1, 1, 1, 1, 2, 1, 65, 1, 0.316227766, 0.669556409, 0.352136337, 3.464101615, 0.1, 0.8, 0.6, 1, 1, 6, 3, 6, 2, 9, 1, 1, 1, 12, 0, 1, 1, 0, 0, 1] 0.027311045841034335\n",
      "Driver [4, 2, 5, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 5, 1, 0, 0, 0.9, 0.5, 0.771362431, 4, 1, -1, 0, 0, 11, 1, 1, 0, 1, 103, 1, 0.316227766, 0.60632002, 0.358329457, 2.828427125, 0.4, 0.5, 0.4, 3, 3, 8, 4, 10, 2, 7, 2, 0, 3, 10, 0, 0, 1, 1, 0, 1] 0.0261231327307869\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# This time our input is an array of two feature arrays\n",
    "x_new = [[0,1,8,1,0,0,1,0,0,0,0,0,0,0,12,1,0,0,0.5,0.3,0.610327781,7,1,-1,0,-1,1,1,1,2,1,65,1,0.316227766,0.669556409,0.352136337,3.464101615,0.1,0.8,0.6,1,1,6,3,6,2,9,1,1,1,12,0,1,1,0,0,1],\n",
    "    [4,2,5,1,0,0,0,0,1,0,0,0,0,0,5,1,0,0,0.9,0.5,0.771362431,4,1,-1,0,0,11,1,1,0,1,103,1,0.316227766,0.60632002,0.358329457,2.828427125,0.4,0.5,0.4,3,3,8,4,10,2,7,2,0,3,10,0,0,1,1,0,1]]\n",
    "\n",
    "# Convert the array or arrays to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted classes.\n",
    "predicted_classes = predictions['result']\n",
    "   \n",
    "for i in range(len(x_new)):\n",
    "    print (\"Driver {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
